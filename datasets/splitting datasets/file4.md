Тема и гость выпуска
Это вопрос науки. Я Алексей Семихатов. Здравствуйте. Очень хочется получить ответ на вопрос: искусственный интеллект
- это всё-таки интеллект? Возможно ли сознание у искусственных нейронных
сетей? Вероятно, простых ответов здесь нет, но как бы то ни было, мы впервые получили нечто отличное от нас, очень
похожее на нас, во всяком случае, в отношении поговорить практически на любые темы. Не ведёт ли отсюда от
искусственных нейронных сетей и искусственного интеллекта дорога или, по крайней мере, тропинка к лучшему
пониманию того, как устроен наш интеллект и наше сознание. У меня в
гостях сегодня Константин Владимирович Анохин. Добро пожаловать в программу.
Добрый вечер. Здравствуйте. Константин Владимирович, доктор медицинских наук, профессор,
директор института перспективных исследований мозга Московского государственного университета и академик
Российской академии наук. И вы много изучали сознания и знаете о нём,
Возможно ли иное сознание, кроме человеческого?
возможно, больше, ну, если не всех, то очень многих. А приближаемся ли мы
сейчас к признанию, что возможны различные сознания не только на нашей
электрохимии, но реализованные совсем по-другому? И, возможно, сознания, но какие-то другие, интеллект, но какой-то
другой? Можно как-то на эту тему внести хоть какую-то ясность в эту быстро развивающуюся и сейчас очень живую тему?
Ну, во-первых, я не очень много изучал сознания. Я начал заниматься этим лет 15
назад. Серьёзно? А, хотя я тут нашёл передачу с Сергеем
Петровичем Копицей, ээ, в конце девяностых годов, где я говорил, что
сознание была посвящена сознанию, я уговорил его, э, сделать
передачу про сознание, потому что это было про вхождение науки в XXI век. И я
убеждал, что сознание будет основной проблемой науки о мозге. э-э в XXI веке.
Но я специалист больше всего по обучению и памяти. Если меня что-то роднит
с ээ искусственными нейронными сетями, то это мои знания не в области сознания,
а в области механизмов обучения памяти. Ну, в отношении разных сознаний. Ну,
обучение и это то, что мы научились очень специальным образом делать для нейронных сетей и вдруг обнаружили, что
они, не знаю, там, если угодно проходят тест тюринга, там, худо бедно, и в общем, прямо похожи на нас. Это
удивительно. Это удивительно. Угу. Это удивительно. Отвечая на ваш вопрос
про возможность разных сознаний. Первая вещь, которая в науке о сознании сейчас
происходит, очень крупная, она так и называется: проблема других
сознания. Other minds. The problem of other minds. Она касается
вопроса о сознании у других живых существ. Иначе говоря, единственные ли
мы в этой вселенной или хотя бы на нашей земле
обладатели этого свойства сознания? И становится ясно, что многие животные
по современному пониманию сознания, отличающемуся от
понимания сознания в XX веке, в середине XX века, когда сознанием считалось
преимущественно то, что свойственно лишь человеку с
развитым языком в культурной среде. Сейчас речь идёт, и это важно для
искусственного интеллекта будет. Сейчас речь идёт о том, что есть высокоразвитое сознание,
Сознание у животных
а, а есть базовое сознание. Угу. А, и есть, поэтому назовём их два вида
существ. Вот мы с вами когнитивные существа типа два. Мы высокопорядковые
когнитивные существа, но мы также когнитивные существа типа один, которые
обладают такими же, видимо, признаками сознания, как другие К1
существа на нашей планеты. Кошечки, собачки, птицы
и консенсус, что птицы обладают сознанием.
А дальше начинается туман, где сейчас проходят очень активные исследования.
Рыбы земноводные, пресмыкающиеся,
насекомые, малюски, осьминогие, шмели.
А они как? Мы в каком-то смысле понижаем планку всё время или мы открываем нечто новое,
более глубокое, в том числе в самих себе, и видим аналоги этого там. Совершенно верно.
Мы не понижаем планку, мы её сразу определили. И есть определение сознания как
способности чувствовать что-то, э, базовое, ощущать, каково это быть.
А это не новое определение. Декарт, когда говорил: "Я мыслю следовательно, я
существую". когета Эргосум. Он писал, что под когета, под когитары я
имею в виду не только рациональное мышление, но и желание, чувства,
намерения и так далее, и так далее. Вот вопрос ээ в следующим. Если
к этому относятся эти чувства, субъективные чувства тоски,
желаний, м восприятия событий в окружающем мире через какие-то
качества, боли, ээ, и это всё наш субъективный опыт, то
вот эта фундаментальная, э, ступень, кто ею обладает?
Чувствуют ли рыбы боль, когда они попадают на крючок или когда там тунца на рыболовецких
суднах там разрубают на куски живого? Чувствуют ли раки или омары ээ боль,
когда их бросают в кипящую воду? Это сложные вопросы. Юис Крол задал его об устрицах уже, да,
почти его. Да, точно, точно. Они настолько сложные, что
у нас вроде бы нет способа это выяснить, потому что нет возможности у них спросить. Есть другие способы. Сознание ээ можно
понять по-настоящему, я в этом убеждён, только изнутри изнутри системы, которая
общается с окружающим миром. Не обязательно спрашивать, вы можете
подсмотреть за признаками того, что происходит внутри. Есть там процессы, которые
научная теория говорит, и есть сознательные процессы, и вы можете это распространять
соответственно на другие объекты. Как быть, например, с новорожденным младенцем? Вы же не можете его спросить.
Сознание младенца
Э на этом основании, что вы скажете? Что
он не обладает сознанием или что это Тероинкогнито? с младенцем просто,
потому что он обладает таким же устройством, как мы, во взрослом состоянии. Мы экстраполяции. Так же, как
я могу сказать, что, наверное, вы обладаете сознанием, я могу предположить это в отношении младенца. Но это не так
просто. Например, эээ ещё до начала восьмидесятых годов в ряде, эээ случаев
в Соединённых Штатах операции на новорожденных младенцах проводились без
наркоза. Какой ужас! Потому что предполагалось, что они не ощущают боли.
А и здесь возникает вопрос: а когда возникает сознание доязыковое у
младенца? В момент рождения, а если недоношенные дети рождаются? Вы смотрите, куда я веду. Я веду к другим
сознаниям. Э, мы более-менее с вами можем говорить, что я обладаю сознанием.
И экстраполируя на это, я думаю, что вы обладаете сознанием. Другие люди в студии обладают сознанием. Дальше мы
идём даже по ступенькам развития гомо сапиенс. У нас возникают вопросы. Мы отклоняемся в сторону к животным. И, ээ,
на основании того, что моей собаки мозг очень похож на мой, я могу также
предположить, что у неё есть сознание. Ээ, кроме того, по каким-то поведенческим признакам, что не очень
надёжно. А как быть с осминогом, у которого абсолютно другая нервная система, и у него восемь, по сути дела,
мозгов в каждой щупальце, когда она может учиться и автономно делать разные
разные вещи. И есть центральная довольно сложная нервная система. У неё там сотни
миллионов клеток. Смотрите, ну и тогда я я ваш я слышу вас, как вы как раз говорите, что вот
ИИ обладает сознанием?
эти вещи, это сознание или что-то очень на него похожее развились эволюционно,
потому что нужно было воспринимать что-то в среде, отклики и так далее. Тогда искусственный интеллект - это
вообще не сознание, потому что он не возник эволюционно в среде. Ему не нужно отклики, ему не нужно выживать, у него
нет переживания по поводу среды. Это нечто совершенно другое. И вдруг оказывается, о чуда, что мы с ним
разговариваем и не понимаем, что разговариваем с машиной. Это другая вещь. Ээ то, что мы с ним
разговариваем и не понимаем, что разговариваемы с машиной, не должно
вести к э заключением, что там внутри кто-то есть.
Всё-таки для того, чтобы понять, есть кто-то внутри или нет, мы должны иметь
теорию механизмов внутреннего устройства сознания, заглянув в машину, несмотря на
то, что в ней нет биологических клеток, нет
жидкостей и химических веществ, нет генома в этих клеток, нет каких-то химических
медиаторов, сигналов между ними, Но операционально она некоторые вещи делает и имеет некоторую архитектуру. Задать
вопрос, те ээ э фундаментальные свойства
алгоритмические, операциональные, которые есть у сознания и которые могут
ээ не зависеть от воплощения в конкретном субстрате, там появляются или
нет, мы можем их подсмотреть. Вот мы к чему должны прийти. Позвольте прояснить противоречие. Я
Формирование и обучение сознания
услышал от вас, что мы хотели бы там в других животных видеть процессы в мозге, как, как вы
говорите, подсмотреть, видеть процессы в мозге, про которые мы знаем, считаем, установили, что они являют отражают
наличие сознания. А с другой стороны, сейчас вы говорите о осознании как о какой-то вещи, которая вырастает
удивительным образом, независимо от носителя. Вот он наш электрохимический носитель, вот уж как сложился. у
собачек, в общем, похожий. Ну, прямо скажем, у осьминогов другой, но всё-таки
не настолько отличающийся, как у вот этих вот, э, больших языковых моделей, где матрицы перемножают. И, ээ, вы
готовы употреблять слово сознание для тех и для других, для всех, включая ээ
искусственный интерес. Если там есть этот специфический процесс, то мы обязаны его называть таким образом. Значит, мы должны понять,
в чём специфика этого процесса. Это раз. Э второе. Я
сейчас должен сказать, что возможно противоречие, которое вы нашли,
оно не такое уж противоречие. Если вы возьмёте и посмотрите на все эти
системы, эволюционировавшие в ситуациях столкновения с какими-то
задачами, с точки зрения процессов обучения, которые мы несколько минут назад ээ обсуждали, то у вас есть
некоторые очень ээ подсказывающие
сходства, намекающие на ней, что у вас есть очень сложные системы, которые кото представляет собой сеть. Эта сеть
глубокая. Эта сеть глубокая в том смысле, что
связь нейронов в элементов ячеек я не буду
использовать даже слово биологическое нейронно, ячеек памяти, которые ээ находятся в этой сети в
глубине, э очень далеко от примитивов внешней
среды и каких-то поверхностей. глубинная переработка идёт, да, сигналов они, совершенно верно, но не не просто
глубинная переработка сигналов, а то, что в этих глубоких слоях нервной сети
каждая клетка получает тысячекратно синтезированный из многих кусочков
внешнего мира и каких-то настроек сети. Ээ сигнал, который потом на следующем
слое ещё обогатился. ээ ещё и ещё и из него начинают вдруг ээ на каких-то слоях
э вытекать очень абстрактные отношение этой системы с поступающим к
ней сигналом. Это второе свойство. И третье, что эта система прошла
и мы с вами, и ребёнок, и осьминок, и птицы. прошла огромное количество циклов
обучения. Она училась, училась, училась взаимодействие с окружающей средой.
Обучение современных языковых моделей
А то, что обучение современных больших языковых моделей требует
фантастического количества электричества, а обучение младенца требует весьма скромного питания и
поддержания жизнедеятельности, это вас не смущает, что это очень это не вы не воспринимаете
их как очень разные процессы. Это просто в силу разности устройств или в силу разности чего столь разные обучения?
Мы этого до конца не знаем. Э, это разные процессы, безусловно, по, э,
просто параметрам, которые вы перечислили, энергии, количество тактов обучения и
так далее, и так далее. Вопрос, насколько это существенно, насколько
вы можете прийти к одному и тому же результату в природе ээ разными путями
внешне? Ээ, если вы будете смотреть на эту дорогу, которая ведёт эту тропинку и
другую тропинку, нижнюю там и верхнюю тропу, они совершенно по-разному выглядят, но закончатся в одном месте.
А это не перестаёт удивлять. Это, вообще-то, недавнее открытие, оно совершенно потрясающе. Не перестаёт удивлять. Я м скажу две
вещи. Я не считаю, что в существующих
системах присутствует сознание. Это раз. Э-э, я не адепт, э-э, идеи, что, э-э,
оно скоро появится, но я не могу исключить этого. Это раз. Э второе, э
что я вижу в этом огромные сложности, если это появится. То есть я бы этой
дорогой, безусловно, не шёл, но это отдельный разговор, трогать это или нет,
и что за этим последует. Теперь проа не перестаёт удивлять. Я где-то в начале
Нейроны у робота
дх000ных годов стал наблюдать в искусственных нейронных сетях пионеров
ээ разработки искусственных сетей, которые не были так эффективны и
популярны в то время. Но в некоторых местах, например, в
институте нейронаук, которым руководил нобелевский лауреат Джеральд Эдельман, они создавали
специальные ээ устройства на нейросетях, которые
назывались мозгооснованные Brain based Devices, которые называли ээ разными
поколениями. У них было имя Дарвин, Дарвин 1, Дарвин 2, Дарвин 3, Дар,
потому что они моделировали в этой искусственной нейронной сети как робот.
Уже сразу они были воплощены, у него было тело, э, выпущенный в какое-то
пространство решает задачи по распознаванию объектов, щупая их или нахождению чего-то в пространстве. И в
2005-2006 году появилась статья, которая привлекла
моё внимание очень сильно. Они показали, что у
этих ээ искусственных нейронных сетях, находящихся в роботе ээ осваивающем
пространство, появляются нейроны, специализированные относительно мест пространства. То есть, поучившись ездить
и собирать кубики, э, в мозге, ээ, искусственном у этого ээ робота,
появились нейроны, которые поразительно похожи по своим свостм, да,
на так называемые нейроны места, обнаруженные в мозге у животных и
человека. Что был Но что было Нобелевской премией? Что было Нобелевской премией 2014 года? Совершенно верно. Почему? Э, и я начал
Прозрачные искусственные нейросети
думать о том, что нам необходимый инструменты. И долго очень ходил с этой
идеей, предлагая в разных местах ээ создать некие прозрачные
искусственные нейронные сети, чтобы видеть, что там происходит, теми же инструментами, которые мы используем как
нейробиологи, когда пытаемся увидеть, что происходит внутри мозга, когда он
учится и появляются эти свойства. А так я и не нашёл единомышленников в
этом, пока не появились искусственно нейронные сети глубокого
обучения уже в 2010 там де-шестнадцатые годы. И возникла проблема, что мы не
знаем, что там происходит. Они что-то делают, и нам нужны эти прозрачные мозги их
прозрачный искусственный интеллект. Это получило название интерпретируемости и понимаемости.
таких искусственных народных сетей. Что там происходит удивительного?
Илья Суцкивер, ученик Джефри Хинтона, получившего
Нейрон сентимента
Нобелевскую премию только что. Безусловно, сверхталантливый
исследователь и визионер, который у Хинтона вместе с Крещевским
создал первую сеть глубокого обучения ALКet, которая научилась распознавать ээ объекты
изображения гораздо лучше, чем экспертные системы.
Перейдя в компанию Open AI в
2000 сенатом ээ где-то году, начав работать с первыми трансформерами, ээ,
архитектурами глубоких нейронных сетей с языковыми языковыми моделями,
обнаружил вещь, на которую он обратил внимание. Точно так же, как я обратил
внимание на 2006, в 2006 году, они учили ээ одну из таких сетей на большом, э,
массиве данных, рецензий ээ на различные
кинофильмы, ээ, м, статьи в журналах,
театральные постановки и так далее, и так далее. А, и научив это, э-э, ээ, э,
большим количеством примеров, начали смотреть, эээ, что происходит внутри сети, и для себя совершенно неожиданно
открыли нейрон сентимента, нейрон, ээ, переживаний, чувственности.
один из нейронов в глубоких слоях именно этой сети,
который активировался, функцией которого фичер
было узнавать настроение ээ текста рецензии. Там, где оно
негативное, он работал одним образом, где сильно позитивно, другим образом,
естественно. Ээ и так ли устроены, в каком смысле наши эмоции,
да. Да. Так и поэтому они начали делать
системы визуализации того, что происходит внутри таких сетей. Он
забеспокоился в этом отношении. Open создал такой микроскоп, который
похож на то, что мне хотелось сделать, который позволял узнать м для разных
нейронов на разных слоях сложных сетей, на что эти нейроны после обучения больше
всего реагируют, что они узнают, что им больше всего нравится. Это называется методика максимизации активации. Смысл
такой, что сети предъявляют, регистрируют ээ степень активации клетки, а предъявляют массу всего-всего
всеего. И из этого делают синтетическое изображение, которое больше всего
возбуждает нейрон. Вот он просто кричит от ээ перевозбуждения. И начали
смотреть, что это за изображение. И оказалось, что там есть нейроны, которые узнают
учили, безусловно, не тренируя на специальные свойства. Есть нейроны, которые распознают цвета. Неважно в чём
они нейроны цветов. Есть нейроны, которые, э, распознают ээ лица ээ
различные исторических персонажей: Гитлера, Трамп, Кеннеди там и так далее. Есть нейроны,
которые распознают, то есть больше всего активируются на лица различных актёров.
Есть нейроны, которые распознают внимание, э выражение эмоций у ээ
человеческих ээ лиц, то есть грусть, гнев, страх и так далее, и так далее.
Этому не учили их. Го. Вы говорите удивительную вещь, что учили совершенно другому. А-а, а,
Возможно ли получить машинное сознание?
возникают тоже, что мы, честно говоря, относили за счёт эволюционного развития.
Я должен из ваших слов сделать какой-то совершенно необычайный вывод. Э, может быть, что поддержите или опровергните
меня, что, э, вот эти вот признаки сознания, которые мы в себе видим, а
есть не столько, есть, конечно, результат эволюции, но есть что ли закономерность, которая возникает в
сложных системах, когда им нужно просто процессировать информацию независимо от архитектуры этих сетей.
Это от вот теперь это открытый вопрос. Если мы это видим,
если мы видим, что у сложных сетей
позиции Суцскивера, которая сильно отличала его от всех нас, ээ, в те годы, в конце
2010, ээ, лет, была следующая. Его всегда интересовали две вещи ээ с
детства. Ну, так он рассказывает ээ искусственный интеллект и сознание.
И его позиция была очень
прямолинейной, что сознание мы в искусственных
нейронных сетях можем получить просто увеличением сложности сети ээ и
количество параметров с одной стороны и второе а массивом обучающей выборки, то
есть объёмом обучения. это возникнет само собой. И действительно, ээ, в
Что такое эмерджентность
искусственном интеллекте последних дву-трёх лет, двух, может быть, лет,
очень, ээ, остро стоит э ээ проблема,
так называемая, проблема эрдженции, возникновения. Чем больше ээ сложность
сети, чем больше параметров, тем больше возникает необычных свойств, на которых
сеть не учили. Она это знает. Мы их не учили. Вдруг выясняют, что она это знает. Она это знает и пользуется этим даже.
Она этим пользуется. Ну да, конечно. Вы её можете об этом спрашивать, она это
активно использует. А и вопрос ээ стоит так: прав Сткивер ээ
в том, что наращивая сложность, мы это получим или там внутри по-прежнему
никого нет? Вы вначале сказали, что вы пессимистичны относительно того, что там
в этих самых сложных глубоких сетях, что там будет сознание.
Я почти так сказал. Э я же исследователь, я могу иметь
какие-то оценочные вещи, но на самом деле я открыт к любым э возможностям.
вероятности их я могу оценивать так, как вы сказали. Пока ээ моё ощущение,
я ээ вёл для этого ощущения или вероятности такого
сценария, специальный термин холодная эмерция. Холодная эмерция.
Да. Я не исключаю, что то, что мы видим, э, и удивляет нас,
ээ, в такой степени, то есть появление субъективно, то есть для этой модели,
специализированных когнитивных ээ элементов внутри, которые отражают то,
что назвает знает массу свойств, на которые её не обучали, что это пример холодной эмерции, что эти
свой свойства возникают, но она ничего не чувствует. А если возвращаемся к
определению сознания, если внутри никого нет нет некого я, который чувствует и
испытывает эти вещи, которые мы называем
эмоциональными выражениями лиц, ээ и они не резонируют у неё как эмоциональные, а
холодно распознаются как эмоциональные, только которые используются дальше, то
мы решили или проблему сознания. То есть мы не достигли этого. Она может имитировать массу вещей, но ничего не
чувствуеть. Она зомби. Вы вот холодная берженция - это
деликатное название для зомби. А вы фактически предлагаете разделить две вещи. Оставить за нами то, что мы в
Если у ИИ найдётся сознание
каком-то смысле, как мы сами думаем, по-настоящему чувствуем. И кошечки, наверное, тоже по-настоящему чувствуют.
Осьминоги, не знаю. А вот всё остальное умение за ними признать, за искусственными нейронными сетями, но при
этом не считать, что в них есть сознание, потому что сознание - это всё-таки что-то ещё поверх возможности
поддерживать беседу на любую тему и знать то, чему не обучали, делать неожиданные выводы, оценивать эмоции и
так далее. Совершенно верно. Ээ единственные слова я предлагаю. Здесь надо поставить
скобки, потому что совершенно неважно, что я предлагаю. Ээ прогресс движется ээ
другими ээ категориями. Ээ никто не будет слушать,
что предлагают отдельные люди. Есть люди, которые действительно говорят: "Давайте не будем этого делать".
Но они реально понимают, что если человек почувствовал возможность
достижения чего-то и учёные почувствовали возможность разработки чего-то, то
коллективно собраться и сказать, что мы этим не будем заниматься, особенно если
это приносит большие деньги и может быть связано с крупными
геополитическими вещами. Это не решение. Но да, я считаю, что нам не надо
наступить на эти грабли, потому что если вы представите, что теперь это не зомби,
а внутри кто-то есть, Угу. то вы столкнётесь с тем, его из розетки из розетки нельзя
вытащить с таким набором этических проблем, из которых я выхода
не вижу. А в заключение всё-таки из-за того, насколько близко мы
Поможет ли развитие ИИ лучше понять человеческий мозг?
довольно неожиданно подошли к почти сознанию, к функциям, к воспроизведению,
к имитации наших функций, э, на вот этих вот железках, что отсюда следует для ээ
традиционного изучения нашего мозга, нашего сознания, нашего людского? Изменятся ли методы? Ээ, перенесём ли мы
оттуда что-то в наше лучшее понимание того, как как наше сознание устроено,
как наш интеллект работает, да? для меня, да, если предыдущие
там с 2005 там по 2020 год 15 лет, я думал о том, как мы можем
перенести то, что я знаю в области нейрофизиологии и нейробиологии для того, чтобы понять, что там,
о'кей, то теперь меня очень сильно интересует вопрос,
зная и исследуя, что происходит в этих искусственных нейронных сетях, Не
является ли это способом понять, ээ, что у нас внутри? И,
э, вопрос, который меня сейчас больше всего интересует, всё-таки что же нас отличает, если там
никого нет? А они всё это имеют. они имеют ээ нейроны с такими же свойствами,
такой же ээ набор вселенную
признаков и параметров. Недавно вышло очень интересно, ну то, что вы говорили, грустный текст, весёлый текст и так далее. Дадада. Ну,
более того, э, вот, ээ, есть, э, такие
разреженные автокодировщики, которые за последний год с помощью них удалось
определить те свойства, который, которыми обладают глубокие
нейронные сети. То есть отдельные свойства, которые ээ при обучении у них возникают, а объём свойств. А и ээ в
недавней вот октябрьской работе Макса Тегмарка из MIT и его команды, они
посмотрели, а как организована геометрия этого пространства свойства, то есть как организована вселенная.
И оказалось, они посмотрели на микромасштабе, на среднем масштабе и макромасштабе всей вселенной. И
оказалось, что это жутко напоминает многие свойства, э, мозга, что на
микромасштабе там есть, они называют это кристалликами, э, маленькие свойства,
которые похожи, которые геометрически организованы как грани с некоторыми
параметрами вместе, определяющими некоторую категорию. В среднем масштабе оказалось, что эти
категории в этой вселенной свойств у модели организованы не
случайно, а анатомическими структурами, ээ долями, как они их называют.
Математика, например, лежит в одной области, физика в другой, язык, ээ, в
третьей. Они группируются и связываются эти кристаллики, образуют эти доли. А,
э, в целом, вся эта галактика, как они называют, ээ, этих свойств, параметров,
она организована не случайно, как можно было бы предполагать, что разные свойства в разных точках и и местах, а
имеет свою тоже геометрию и архитектуру. То есть, ээ, в результате, казалось бы,
такого примитивного тренировки и нейронных сетей на одно, э, формируются,
э, сложнейшие структуры внутри них, которые мы только начинаем изучать. И
вопрос, подскажет ли это нам что-то о том, как
они формируются у нас и что нас всё-таки отличает принципиально?
Тем не менее, чего им не хватает. Э, мой ответ, что у них пока нет
желаний. А, замечательное место, чтобы пожелать вам прогресса. а-а желание разобраться в
этом не ослабевающего, а всем нашим зрителям интереса к этой чрезвычайно
важной теме, в том числе важной для того, чтобы узнать, каковы мы сами, как мы думаем, как мы чувствуем. Большое
спасибо за ваш интересный рассказ. Всего хорошего, до свидания.

