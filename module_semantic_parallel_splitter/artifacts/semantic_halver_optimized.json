{
  "halver": {
    "traces": [],
    "train": [],
    "demos": [
      {
        "augmented": true,
        "text": "I really do appreciate that you're all here. I'm going to try and make this as painless as possible. We're not going to do an interactive part. We're going to talk through stuff. I'm happy to go off script. I'm happy to take questions if there's stuff we want to explore at any moment in this. My goal is I'd like to share with you a lot of things that I've learned. Um I'm going to try and make them as actionable as possible. So there is real stuff to do here. Um more than we might in like a more high level talk. But let's be very honest, it is late. It is a lot. It is long. Let's uh let's talk about MCP. I'm hoping that folks here are interested in MCP and that's why you came to this talk. If you're here to learn about MCP, this might be a little bit of a of a different bent. Just show of hands, heard of MCP, used MCP, written in MCP server. Okay. Uh, anyone feel uncomfortable with MCP, which is 100% fine. We can tailor. Okay, then I would say let's let's just go let's dive in. Um, this is who I am. Uh, I'm the founder and CEO of a company called Prefect Technologies. For the last seven or eight years, we've been building um data automation software and orchestration software. Before that, I was a member of the Apache Airflow PMC. Um I originally started Prefect to graduate those same orchestration ideas into data science. Today, we operate the full stack. And then um a few years ago, I I developed an agent framework called Marvin, which I would not describe as wildly popular, but it was my leg into the world of AI, at least from a developer experience standpoint, and learned a lot from that. And then more recently, I introduced a piece of software called fastmcp, which has is is wildly wildly popular, maybe even too popular. And um hence my status today. I'm a little overwhelmed. Uh I find myself back in an open source maintenance seat, which I haven't been in in a few years, which has been a hell of a lot of fun. Um but the most important thing is that fastmcp has given me a very specific vantage point that is really the basis for this talk today. This is our downloads. I've never seen anything like this. I've never worked on a project like this. It was downloaded a million and a half times yesterday. Um there's a lot of MVP servers out there and um fastp is just it's it's it's become the de facto standard way to build MCP servers. Um I introduced it almost exactly a year ago. As many of you are probably aware, MCP itself was introduced almost exactly a year ago and a few days later I introduced the first version of fast MCP. Uh David atropic uh called me up said I think this is great. I think this is how people should build servers. We put a version of it into the official SDK which was amazing. And then as um as MCP has gone crazy in the last year, we found it actually to be constructive to position fast MCP uh as I'm maintaining it as the highle interface to the MCP ecosystem while the SDK SDK focuses on the low-level primitives",
        "first_block": "I really do appreciate that you're all here. I'm going to try and make this as painless as possible. We're not going to do an interactive part. We're going to talk through stuff. I'm happy to go off script. I'm happy to take questions if there's stuff we want to explore at any moment in this. My goal is I'd like to share with you a lot of things that I've learned. Um I'm going to try and make them as actionable as possible. So there is real stuff to do here. Um more than we might in like a more high level talk. But let's be very honest, it is late. It is a lot. It is long. Let's uh let's talk about MCP. I'm hoping that folks here are interested in MCP and that's why you came to this talk. If you're here to learn about MCP, this might be a little bit of a of a different bent. Just show of hands, heard of MCP, used MCP, written in MCP server. Okay. Uh, anyone feel uncomfortable with MCP, which is 100% fine. We can tailor. Okay, then I would say let's let's just go let's dive in.",
        "split_index": 991
      },
      {
        "augmented": true,
        "text": "we're going to remove the fastm vocabulary from the low-level SDK um in a couple of months. It's become a little bit of it's it's too confusing that there are these two things called fast MCP. So fast MTP will be a highle interface to the world and um as a result we see a lot of um not great MCP servers. I I named the talk after this meme and then it occurred to me like do people even know what this meme is anymore? Like this this to me is very funny and very topical and then it's from like a 1999 episode of Futurama. So if you haven't seen this, my talk's title is not meant to be mean. I'm sort of an optimist. I choose to interpret this as but you can do better. And so we're going to find ways to do better. That is the goal of today's talk. In fact, to be more precise, what I want to do today is I would really like to build an intuition for a gentic product design. Um I don't see this talked about nearly as much as it should be given how many agents are using how many products today. And what I mean by this is the exact analog of what it would be if I were if I were giving a talk on how to just build a good product for a user, for a human. And we would talk about human interface guidelines and we talk about user experience and we talk about stories. And I found it really instructive to start talking about those things from an agentic perspective because what else is an MCP server but an interface um for an agent and we should design it for the strengths and weaknesses of those agents in the same way that we do everything else. Now when I put this thought in the world I very very very frequently get this push back which is but if a human can use an API why can't an AI and there are so many things wrong with this question and the number one thing that's wrong with this question is that it has a assumption that I see in so much of AI product design and it drives me nuts which is that AIs are perfect or they're oracles or they're good at everything and they are very very very powerful tools but I'm assuming based on your responses before. I think everyone in this room has some scars of the fact that they are fallible or they are limited or you know they're imperfect. And so I don't like this question because it presumes that they're like magically amazing at everything. But I really don't like this question. This is a literal question I've got and I didn't paraphrase it. I really don't like this question because humans don't use APIs. Very very rarely do humans use APIs. Humans use products. We do anything we can to put something between us and an API. We put a website. we put a SDK, we put a client, we put a mobile app. We we do not like to use APIs unless we have to or we are the person responsible for building um that interface. And so one of my core arguments um and why I love MCP so much is that I believe that agents deserve their own interface that is optimized for them and uh their own use case.",
        "first_block": "we're going to remove the fastm vocabulary from the low-level SDK um in a couple of months. It's become a little bit of it's it's too confusing that there are these two things called fast MCP. So fast MTP will be a highle interface to the world and um as a result we see a lot of um not great MCP servers. I I named the talk after this meme and then it occurred to me like do people even know what this meme is anymore? Like this this to me is very funny and very topical and then it's from like a 1999 episode of Futurama. So if you haven't seen this, my talk's title is not meant to be mean. I'm sort of an optimist. I choose to interpret this as but you can do better. And so we're going to find ways to do better. That is the goal of today's talk. In fact, to be more precise, what I want to do today is I would really like to build an intuition for a gentic product design.",
        "split_index": 878
      },
      {
        "augmented": true,
        "text": "s what I want to motivate today, uh we have to think a little bit about what is the difference between a human and an AI. And it's one of these questions that's like sounds really stupid when you say it out loud, but it's instructive to actually go through. And I'd like to make the argument to you that it exists on these three um dimensions of discovery, iteration, and context. And so just to begin, humans, we find discovery really cheap. We tend to do it once. If you think if if any of you have had to implement something against a REST API, what do you do? You call up the docs or you go in Swagger, whatever it is, you call it up, you look at it one time, you figure out what you need, you're never going to do that again. And so, while it may take you some time to do the discovery, it is cheap in the lifetime of the application you are building. AIS, not so much. Every single time that thing turns on, it shakes hands with the server. It learns about the server. It enumerates every single tool and every single description on that server. So discovery is actually really expensive for agents. It consumes a lot of tokens. Um, next, iteration. Same idea. If you're a human developer and you're writing code against an API, you can iterate really quickly. Why? Because you do your one-time discovery. You figure out the three routes you're going to call and then you write a script that calls them one after another as fast as your language allows. So iteration is really cheap. And if that doesn't work, you just run it again until it does. Iteration is cheap. is fast. Um for agents, I think we all know iteration is slow. Iteration is the enemy. Every additional call um subject to your caching setup also sends the entire history of all previous co calls over the wire. Like it is just you do not want to iterate if you can avoid it. And so that's going to be an important thing that we take into consideration. And the last thing is on context. And this is a little bit handwavy, but it is important as humans in this conversation. I'm talking, you're hearing me, and you're comparing this to different memories you have and different experiences you have on different time scales, and it's all doing wonderful, amazing things in your brain. And when you plug an LLM uh into any um given use case, it remembers the last 200,000 tokens it saw. And that's the extent of its um memory plus whatever is, you know, embedded somewhere in its in its weights and that's it. And so we need to be very very conscious of the fact that it has a very small brain at this moment. I I think it is a lot closer to when people talk about sending, you know, Apollo 11 to the moon and and with like 1 kilobyte of RAM, whatever it was. I think that's actually how we need to think about these things that frankly feel quite magical because they go and uh open my PRs for me or whatever it is that they do. Um, so these are the three key dimensions in my mind of what is different and we should not build",
        "first_block": "s what I want to motivate today, uh we have to think a little bit about what is the difference between a human and an AI. And it's one of these questions that's like sounds really stupid when you say it out loud, but it's instructive to actually go through. And I'd like to make the argument to you that it exists on these three um dimensions of discovery, iteration, and context. And so just to begin, humans, we find discovery really cheap. We tend to do it once. If you think if if any of you have had to implement something against a REST API, what do you do? You call up the docs or you go in Swagger, whatever it is, you call it up, you look at it one time, you figure out what you need, you're never going to do that again. And so, while it may take you some time to do the discovery, it is cheap in the lifetime of the application you are building. AIS, not so much. Every single time that thing turns on, it shakes hands with the server. It learns about the server. It enumerates every single tool and every single description on that server. So discovery is actually really expensive for agents. It consumes a lot of tokens.",
        "split_index": 1134
      },
      {
        "augmented": true,
        "text": "APIs that are good for humans on any of these dimensions and pretend that they are also good for agents. And one way that I've kind of started talking about this is this idea which is an agent can find a needle in a hay stack. The problem is it's going to look at every piece of hay and decide if it's a needle. And that's like not literally true, but it is in an intuitive sense how we should think about what we're putting in front of the agents and how we're posing a problem. And an MCP server is nothing but an interface to that problem andor solution. And so finally to go back to our product intuition statement, I argued to you that the most important word in the universe for MCP developers is curate. How do you curate from a huge amount of information which might be amenable for a human developer a interface that is appropriate for one of these extremely limited AI agents at least on the dimensions that we just went through. Um, and that sort of brings us to this slide, YMCP. And I almost made this like the Derek Zoolander slide like but why MCP? Like but I just told you why MCP Derek. It's because it does all of these things. It gives us a standard way of communicating uh information to agents in a way that's controllable where we can control not only how it's discovered but also how it is acted on. There's a big asterisk on that because client implementations in the MCP space right now are not amazing and they do some things that are themselves not compliant with the MCP spec. Maybe at the end we'll get into that. It's not directly relevant to now except that all we can do is try to build the best servers we can subject to the limitations of the clients that will use them. And again, I put this in here. I think we don't need to go through uh what MCP is for this audience. So, we're going to move quickly through this. But it is, of course, for the for the for the sake of the transcript, the cliche is that it's USBC uh for the internet. It is a standard way to connect LLMs and either tools or um data. And if you haven't seen fast MCP, this is what it looks like to build a fully fully functional MCP server. This one, I live in Washington DC. the subway is often on fire there and so this checks whether or not the subway is on fire and um indeed it is. Now the question we are here to actually explore is why are there so many bad MCP servers? Maybe a better question is do you all agree with me that there are many bad MCP servers? I sort of declare this as if it's true. I I'm not trying to make a controversial statement. There are many bad MCP servers in the world. I see a lot of them because people are using my framework to build them. It does that surprise anyone that I'm sort of declaring that I'm genuinely I'm I'm curious if that's a if I'm made an assumption. I don't in my experience I I won't say every every MCB I I came up to is like that but a lot of them are like AI rubbers. They just put a like stringify the content of the API and that's an",
        "first_block": "APIs that are good for humans on any of these dimensions and pretend that they are also good for agents. And one way that I've kind of started talking about this is this idea which is an agent can find a needle in a hay stack. The problem is it's going to look at every piece of hay and decide if it's a needle. And that's like not literally true, but it is in an intuitive sense how we should think about what we're putting in front of the agents and how we're posing a problem. And an MCP server is nothing but an interface to that problem andor solution. And so finally to go back to our product intuition statement, I argued to you that the most important word in the universe for MCP developers is curate. How do you curate from a huge amount of information which might be amenable for a human developer a interface that is appropriate for one of these extremely limited AI agents at least on the dimensions that we just went through.",
        "split_index": 939
      },
      {
        "text": "The tools it receives on the first contact and puts them in a SQLite database and it doesn't care what you do. It doesn't care about the fact that the spec allows you to send more information. I think your solution would get around this because it's a tool call. But um many of the first attempts that people use to use spec compliant techniques for getting around this problem such as notifications fail in cloud desktop. Usually you failed before this in cloud desktop. I'm not a fan of cloud desktop from MCP server. I think it's a real missed opportunity because it is such a flagship product of the company that has introduced MCP. I think it's a real missed opportunity. Cloud code is great. um uh it it caches everything in SQLite database so it like doesn't matter uh what you do um techniques similar to what you've described where you provide mechanisms for learning more about a tool that's a great idea I really like that um there is a challenge where now you are back in a sort of flatten arguments world because you have met tools now where I need to use tools to learn about tools and use to tools to call tools in some extreme cases or beyond so you need to design this very carefully that's why it usually does show up as a dedicated ated product. So thank you for sharing that. Um uh there are many really interesting techniques for trying to solve this problem. Yes. So you talk about um progressive disclosure. Do you use um masking? So for example, I connect to my Kubernetes server and my credentials only give me certain rights. So therefore there are 28 tools that I don't have access to. So therefore, you don't need to do that. So when you say do I do I support that? Do you mean does MCP support that or do I in my product support that? Yeah, I was just asking something I've read about. Okay. So so the spec makes no claim about this. The spec says when you call list tools you get tools back and how that happens is is up to up to implementation. Um, fast MCP makes that an overridable hook through middleware, but again makes no claim on how that is. Prefix commercial products, which I'm not here to pitch, allow per tool masking on any basis. And we see that as like a place to have an opinionated in the commercial landscape as opposed to an opinion in the open source landscape as opposed to the protocol which should have no opinion at all. So if that's interesting, we can chat about this. You might be getting into this but if you take this problem the example J might have mentioned kind of table of contents approach guess approach is what split over the four different chunks or maybe the 800 don't all justify having their own server like what was the solution for them they can't do it they there's no solution that allowed them to have as much information as they wanted on the on the contact center window they have they didn't need it they didn't need it um and and it became a design question and and frankly it was this call was probably four months ago",
        "ground_truth_first_block": "The tools it receives on the first contact and puts them in a SQLite database and it doesn't care what you do. It doesn't care about the fact that the spec allows you to send more information. I think your solution would get around this because it's a tool call. But um many of the first attempts that people use to use spec compliant techniques for getting around this problem such as notifications fail in cloud desktop. Usually you failed before this in cloud desktop. I'm not a fan of cloud desktop from MCP server. I think it's a real missed opportunity because it is such a flagship product of the company that has introduced MCP. I think it's a real missed opportunity. Cloud code is great. um uh it it caches everything in SQLite database so it like doesn't matter uh what you do um techniques similar to what you've described where you provide mechanisms for learning more about a tool that's a great idea I really like that um there is a challenge where now you are back in a sort of flatten arguments world because you have met tools now where I need to use tools to learn about tools and use to tools to call tools in some extreme cases or beyond so you need to design this very carefully that's why it usually does show up as a dedicated ated product. So thank you for sharing that."
      },
      {
        "text": "is so excited that they're rolling out MCP and I met with the engineering team and and just to be clear, this is an incredibly forward-thinking, high-erforming um, massive company that I incredibly respect. I won't say who they are, but I really respect them. and they got on the call and they were so excited and they were like, \"We're in the process of converting our stuff to MCP so that we can use it.\" And they had a a strong argument why it actually had to be their API. So that's not even the punch line of the story, which is a whole other story in in and of itself, but it fundamentally came down to this. They had 800 endpoints that had to be exposed to which I had this thought, which if by the time you finish reading this, this is the token budget for each of those 800 tools. if you assume 200,000 um um tokens in the context window. So if each of those 800 tools had only this much space to document itself, not even document itself, share its schema, share its name plus documentation, this is the amount of space you would get. And when you were done taking up this space because you were so careful and each tool really fit in this, you would lobomize the agent on handshake because it would have no room for anything else. So the token budget really matters. um if this agent connected to a server with one more tool that had a one-word dock string, it would just fail. It would just have a over effectively an overflow, right? So, the token budget matters. Um there is probably a budget that's appropriate for whatever work you're doing. You may know what it is, you may not know what it is. Pretend you know what it is and be mindful of it. Um in a worst case scenario, try to be parsimmonious. Try to be as efficient as possible. That's why we do experiments like sending additional instructions in the error message. It's one way to save on the token budget on handshake. And the handshake is painful. Um I'm not sure folks know that uh when an when an LLM connects to an NCP server, it typically does download all the descriptions in one go so that it knows what's available to it. And it's usually not done in like a progressively disclosed way. That is done outright.",
        "ground_truth_first_block": "is so excited that they're rolling out MCP and I met with the engineering team and and just to be clear, this is an incredibly forward-thinking, high-erforming um, massive company that I incredibly respect. I won't say who they are, but I really respect them. and they got on the call and they were so excited and they were like, \"We're in the process of converting our stuff to MCP so that we can use it.\" And they had a a strong argument why it actually had to be their API. So that's not even the punch line of the story, which is a whole other story in in and of itself, but it fundamentally came down to this. They had 800 endpoints that had to be exposed to which I had this thought, which if by the time you finish reading this, this is the token budget for each of those 800 tools. if you assume 200,000 um um tokens in the context window. So if each of those 800 tools had only this much space to document itself, not even document itself, share its schema, share its name plus documentation, this is the amount of space you would get. And when you were done taking up this space because you were so careful and each tool really fit in this, you would lobomize the agent on handshake because it would have no room for anything else."
      },
      {
        "text": "now and it was just call after call after call after call like this. Um, which made me realize we need to have talks more like this and just talk about what it is to design a product for an agent. My worry is MCP is viewed as infrastructure or a transport technology and it is and I'm very excited. I think by a year from now we will be talking about context products as opposed to MCP servers. I'm very excited about that. We'll move past the transport. Um but we need to figure out how to use it and so so I think that's how we talk about it. Um the only other alternative that I have discussed with a few folks a few companies when you have a problem like this is if you control the client much more interesting things become available to you. Um if you can instruct your client to do things a certain way for example if you have a mobile app that presents an agentic interface to an end user you control the client is what I mean by that. um or if it's internal and you can dictate what what client or what custom client a team uses. Now you can do much more interesting things because you actually do know a lot more about that token budget and how to optimize it. But for an external facing server, there's not a good there's not a good solution. I think by now we have talked through all of this. So I'll leave it for uh posterity uh in the interest of time. Um, we talked about curate as a key verb earlier in this talk. Um, it is, I would argue, what we have been doing in each of these little vignettes that we've been working through with the code. We are curating the same information set down to one that is more amendable and more recognizable for an agent. Um, 50 tools is where I draw the line where you're going to have performance problems. I think it seems really low to a lot of people. Some people will talk about it even lower than that. Some people might talk about it higher. If you have more than 50 tools on a server without knowing anything else about it, I'm going to start to think that it's not a great server. Um, the GitHub server has, I think, 170 tools. Does that mean it's not a great server? No. There's a good argument there. And the GitHub team has put out a lot of really interesting blog posts on semantic routing that they're doing. They had one just yesterday actually on like some interesting techniques they're using. Um, uh, there's software like, um, like the one you mentioned a moment ago, sir, which which helps with this problem. So having a lot of tools like that does not automatically make it a bad server, but it is a smell and it does make me wonder, can we split them up? Do you have admin tools mixed in with user tools? Could we name space these tools differently? Would it be worthwhile having two servers instead of one? Um, that is a little bit of a smell. If you can get down to 515, that would be ideal. I know that's not achievable for most people. So it's one of those actionable but maybe not so actionable little tips. It's an aspir",
        "ground_truth_first_block": "now and it was just call after call after call after call like this. Um, which made me realize we need to have talks more like this and just talk about what it is to design a product for an agent. My worry is MCP is viewed as infrastructure or a transport technology and it is and I'm very excited. I think by a year from now we will be talking about context products as opposed to MCP servers. I'm very excited about that. We'll move past the transport. Um but we need to figure out how to use it and so so I think that's how we talk about it. Um the only other alternative that I have discussed with a few folks a few companies when you have a problem like this is if you control the client much more interesting things become available to you. Um if you can instruct your client to do things a certain way for example if you have a mobile app that presents an agentic interface to an end user you control the client is what I mean by that. um or if it's internal and you can dictate what what client or what custom client a team uses. Now you can do much more interesting things because you actually do know a lot more about that token budget and how to optimize it. But for an external facing server, there's not a good there's not a good solution."
      },
      {
        "text": "...you might actually document how to recover from the most common failures. And so it's a very weird form of progressive disclosure of information where you are acknowledging that it is likely that this agent will get its first call wrong, but based on how it gets it wrong, you actually have an opportunity to send more information back in an error message. Um, as I said, this is a kind of a not an amazing way to think about building software, but it is the ultimate version of what I'm recommending, which is be as helpful as possible in your error messages. Do go overboard. They become part of, as far as the agent is concerned, its next prompt. And so, they do matter. Um, if they are too aggressive or too scary, it may avoid the tool permanently. It may decide the tool is inoperable. Um, so errors really matter. The MCP spec has support for annotations, which is a restricted subset of annotations that you can place on various components. One of them for tools is whether or not it's readonly. And if you supply this optionally, clients can choose to treat that tool a little bit differently. And so the motivation behind the readonly hint was basically to help with setting permissions. Respects the token budget. I think the meme right now is that the GitHub server ships like 200,000 tokens when you handshake with it, something like that. Um, this is a real thing. And I don't think it makes the GitHub server automatically bad. I think it's actually makes endemic on folks like myself who build frameworks and folks who build clients to find ways to actually solve this problem because the answer can't always be do less.",
        "ground_truth_first_block": "...you might actually document how to recover from the most common failures. And so it's a very weird form of progressive disclosure of information where you are acknowledging that it is likely that this agent will get its first call wrong, but based on how it gets it wrong, you actually have an opportunity to send more information back in an error message. Um, as I said, this is a kind of a not an amazing way to think about building software, but it is the ultimate version of what I'm recommending, which is be as helpful as possible in your error messages. Do go overboard. They become part of, as far as the agent is concerned, its next prompt. And so, they do matter. Um, if they are too aggressive or too scary, it may avoid the tool permanently. It may decide the tool is inoperable. Um, so errors really matter."
      }
    ],
    "signature": {
      "instructions": "Проанализируй фрагмент текста и определи границы первого смыслового куска.\n\nТвоя задача - найти в тексте первый логически завершенный смысловой блок с самого начала.\nЭтот кусок должен быть самодостаточным по смыслу и логически завершенным. Например, байка, или кейс.\nНе обрывай предложения и не обрывай логические цепочки.\n\nВажно:\n- Возвращай ТОЧНУЮ подстроку из исходного текста\n- НЕ измений исходный текст первого куска, оставь текст полностью как есть\n- Не переводи, не форматируй, не изменяй текст\n- Просто выдели смысловой кусок как есть",
      "fields": [
        {
          "prefix": "Text:",
          "description": "Полный текст для анализа и разделения на куски."
        },
        {
          "prefix": "First Block:",
          "description": "Первый смысловой кусок из текста - точная подстрока без изменений."
        }
      ]
    },
    "lm": null
  },
  "metadata": {
    "dependency_versions": {
      "python": "3.12",
      "dspy": "3.1.0",
      "cloudpickle": "3.1"
    }
  }
}
